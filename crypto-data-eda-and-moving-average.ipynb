{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034742,
     "end_time": "2024-06-25T17:25:41.454156",
     "exception": false,
     "start_time": "2024-06-25T17:25:41.419414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis-focusing on Moveing Averages with Crypto-currency Data\n",
    "\n",
    "### Getting the Data\n",
    "\n",
    "I have uploaded to this [Kaggle Dataset](https://www.kaggle.com/paulrohan2020/crypto-data) which is a zipped file with 26,320 `.csv` files containing the top cryptocurrencies on https://coinmarketcap.com/ by market cap worldwide. After 20:45:05 on August 4, data was collected every five minutes for three months.\n",
    "\n",
    "Also I have uploaded the 9,432 .csv files based on which this below EDA analysis done into my [Github repository](https://github.com/rohan-paul/Cryptocurrency-Kaggle/tree/main/Notebooks/kaggle/input/crypto-data).\n",
    "\n",
    "This dataset is from **CoinMarketCap Data** From August 4 to November 4, 2017\n",
    "\n",
    "Filenames represent the date and time at which the data was collected: ymd-hms. The data in cr_20170804-210505.csv was collected on August 4, 2017 at 21:05:05.\n",
    "\n",
    "### The Columns in the Data\n",
    "\n",
    "symbol,ranking by market cap,name,market cap,price,circulating supply,volume,% 1h,% 24h,% 1wk\n",
    "\n",
    "# Some basics on Moving Average\n",
    "\n",
    "##### Moving averages are one of the most often-cited data-parameter in the space of Stock market trading, technical analysis of market and is extremely useful for forecasting long-term trends.. And beyond its use in financial time series this is intensively used in signal processing to neural networks and it is being used quite extensively many other fields. Basically any data that is in a sequence.\n",
    "\n",
    "The most commonly used Moving Averages (MAs) are the simple and exponential moving average. Simple Moving Average (SMA) takes the average over some set number of time periods. So a 10 period SMA would be over 10 periods (usually meaning 10 trading days).\n",
    "\n",
    "Rolling mean/Moving Average (MA) smooths out price data by creating a constantly updated average price. This is useful to cut down ‚Äúnoise‚Äù in our price chart. Furthermore, this Moving Average could act as ‚ÄúResistance‚Äù meaning from the downtrend and uptrend of stocks you could expect it will follow the trend and less likely to deviate outside its resistance point.\n",
    "\n",
    "### Factors to choose the Simple Moving Average (SMA) window or period\n",
    "\n",
    "In order to find the best period of an SMA, we first need to know how long we are going to keep the stock in our portfolio. If we are swing traders, we may want to keep it for 5‚Äì10 business days. If we are position traders, maybe we must raise this threshold to 40‚Äì60 days. If we are portfolio traders and use moving averages as a technical filter in our stock screening plan, maybe we can focus on 200‚Äì300 days.\n",
    "\n",
    "---\n",
    "\n",
    "### Now some real-world Exploratory Data Analysis with real Crypto-currency data from Coinbase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-25T17:25:41.526534Z",
     "iopub.status.busy": "2024-06-25T17:25:41.525740Z",
     "iopub.status.idle": "2024-06-25T17:25:42.497285Z",
     "shell.execute_reply": "2024-06-25T17:25:42.496476Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.450434Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.010124,
     "end_time": "2024-06-25T17:25:42.497431",
     "exception": false,
     "start_time": "2024-06-25T17:25:41.487307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2024-06-25T17:25:42.568394Z",
     "iopub.status.busy": "2024-06-25T17:25:42.567270Z",
     "iopub.status.idle": "2024-06-25T17:25:42.570956Z",
     "shell.execute_reply": "2024-06-25T17:25:42.570251Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.460669Z"
    },
    "papermill": {
     "duration": 0.041431,
     "end_time": "2024-06-25T17:25:42.571102",
     "exception": false,
     "start_time": "2024-06-25T17:25:42.529671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_dir = '/kaggle/input/crypto-data/Crypto-Coinmarketcap/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-25T17:25:42.642079Z",
     "iopub.status.busy": "2024-06-25T17:25:42.641261Z",
     "iopub.status.idle": "2024-06-25T17:25:42.723106Z",
     "shell.execute_reply": "2024-06-25T17:25:42.721558Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.471969Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.120236,
     "end_time": "2024-06-25T17:25:42.723318",
     "exception": true,
     "start_time": "2024-06-25T17:25:42.603082",
     "status": "failed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/crypto-data/Crypto-Coinmarketcap/cr_20170804-034052.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-28bcf9bffc38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnRowsRead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'cr_20170804-034052.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnRowsRead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'cr_20170804-035004.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnRowsRead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/crypto-data/Crypto-Coinmarketcap/cr_20170804-034052.csv'"
     ]
    }
   ],
   "source": [
    "nRowsRead = 1000 \n",
    "df1 = pd.read_csv(file_dir+'cr_20170804-034052.csv', delimiter=',', nrows = nRowsRead)\n",
    "df2 = pd.read_csv(file_dir+'cr_20170804-035004.csv', delimiter=',', nrows = nRowsRead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:23:20.504025Z",
     "iopub.status.busy": "2021-06-23T22:23:20.503577Z",
     "iopub.status.idle": "2021-06-23T22:23:20.510366Z",
     "shell.execute_reply": "2021-06-23T22:23:20.509105Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.503978Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nRowsRead = 1000 \n",
    "nRow, nCol = df1.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:23:20.512616Z",
     "iopub.status.busy": "2021-06-23T22:23:20.512317Z",
     "iopub.status.idle": "2021-06-23T22:23:20.541011Z",
     "shell.execute_reply": "2021-06-23T22:23:20.539705Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.512588Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Distribution graphs (histogram/bar graph) of sampled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:23:20.552316Z",
     "iopub.status.busy": "2021-06-23T22:23:20.552019Z",
     "iopub.status.idle": "2021-06-23T22:23:20.567119Z",
     "shell.execute_reply": "2021-06-23T22:23:20.566056Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.552287Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.dataframeName = 'cr_20170804-035004.csv'\n",
    "nRow, nCol = df2.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:23:20.568786Z",
     "iopub.status.busy": "2021-06-23T22:23:20.568481Z",
     "iopub.status.idle": "2021-06-23T22:23:20.592169Z",
     "shell.execute_reply": "2021-06-23T22:23:20.591307Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.568759Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Distribution graphs (histogram/bar graph) of sampled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:23:20.633306Z",
     "iopub.status.busy": "2021-06-23T22:23:20.632937Z",
     "iopub.status.idle": "2021-06-23T22:23:20.642619Z",
     "shell.execute_reply": "2021-06-23T22:23:20.641423Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.633273Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df1.shape)\n",
    "print(df1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:23:20.645203Z",
     "iopub.status.busy": "2021-06-23T22:23:20.644736Z",
     "iopub.status.idle": "2021-06-23T22:23:21.495424Z",
     "shell.execute_reply": "2021-06-23T22:23:21.494382Z",
     "shell.execute_reply.started": "2021-06-23T22:23:20.645167Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls $file_dir | wc -l \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:23:21.497257Z",
     "iopub.status.busy": "2021-06-23T22:23:21.496784Z",
     "iopub.status.idle": "2021-06-23T22:23:21.637964Z",
     "shell.execute_reply": "2021-06-23T22:23:21.636935Z",
     "shell.execute_reply.started": "2021-06-23T22:23:21.497181Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(file_dir, \"*.csv\"))\n",
    "files_list = all_files[:9432]\n",
    "df1 = pd.read_csv(files_list[0])\n",
    "df2 = pd.read_csv(files_list[1])\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:23:21.639897Z",
     "iopub.status.busy": "2021-06-23T22:23:21.63959Z",
     "iopub.status.idle": "2021-06-23T22:23:21.660628Z",
     "shell.execute_reply": "2021-06-23T22:23:21.659093Z",
     "shell.execute_reply.started": "2021-06-23T22:23:21.639868Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Code to combine 9432 .csv files into a single dataframe and then\n",
    "### Filter data for 'Symbol' column == 'BTC'\n",
    "### generating a .csv file out that combined-single dataframe to work with.\n",
    "\n",
    "As we can see above, all these files have the same columns so it seems reasonable to concatenate everything into one dataframe. However, I want to keep track of the file names because that's the only reference to the date of the records.\n",
    "\n",
    "- First, creating a list of dataframes with the filenames in a \"file_name\" column\n",
    "- Then concatenate them all into one big dataframe\n",
    "\n",
    "#### The  below are the scripts for that, but I have commented-out all of these lines,\n",
    "#### as obviously I dont want to run this huge process-intensive steps every time\n",
    "#### of creating a single DataFrame out of 9432 .csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "##### The above dataframe has all the SYMBOLS of all the crypto-currencies as was in the individual .csv files.\n",
    "##### But now I want to extract ONLY the symbol 'BTC' for Bitcoin for the further analysis.\n",
    "\n",
    "Below is the code for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### Now generating a .csv file contain which will be used as a training dataset\n",
    "#### This file is created out that combined-single dataframe (that I earlier created from 9432 .csv files )\n",
    "as obviously I dont want to run this huge process-intensive step of creating a single\n",
    "Data-Frame out of 9432 .csv files.\n",
    "\n",
    "Below code is commented out as well, because I have run this script just once to create the file.\n",
    "And then I have saved the file (to be used as an input) both in Kaggle and also for my local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.363592Z",
     "iopub.status.busy": "2021-06-23T22:24:38.36312Z",
     "iopub.status.idle": "2021-06-23T22:24:38.440433Z",
     "shell.execute_reply": "2021-06-23T22:24:38.43938Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.363545Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_btc_train = pd.read_csv(\"/kaggle/input/crypto-data/train_BTC_combined.csv\")\n",
    "\n",
    "original_btc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.442823Z",
     "iopub.status.busy": "2021-06-23T22:24:38.442518Z",
     "iopub.status.idle": "2021-06-23T22:24:38.449845Z",
     "shell.execute_reply": "2021-06-23T22:24:38.448733Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.44279Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_btc_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "Lets analyze the dataframe with .info() method. This method prints a concise summary of the data frame, including the column names and their data types, the number of non-null values, the amount of memory used by the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.451712Z",
     "iopub.status.busy": "2021-06-23T22:24:38.45133Z",
     "iopub.status.idle": "2021-06-23T22:24:38.483919Z",
     "shell.execute_reply": "2021-06-23T22:24:38.483008Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.451605Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_btc_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "As shown above, the data sets do not contain null values but some of the columns where I expected numerical or float values, instead contain object Dtype like the 'market cap' column.\n",
    "\n",
    "Also starting with 'file_name' upto '1wk' columns dont have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.485488Z",
     "iopub.status.busy": "2021-06-23T22:24:38.485156Z",
     "iopub.status.idle": "2021-06-23T22:24:38.530198Z",
     "shell.execute_reply": "2021-06-23T22:24:38.528965Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.485459Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"All Features list\", original_btc_train.columns.tolist())\n",
    "print(\"\\nMissing Values\", original_btc_train.isnull().any())\n",
    "print(\"\\nUnique Values \", original_btc_train.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.532838Z",
     "iopub.status.busy": "2021-06-23T22:24:38.532499Z",
     "iopub.status.idle": "2021-06-23T22:24:38.573408Z",
     "shell.execute_reply": "2021-06-23T22:24:38.572083Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.532808Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_btc_train['market cap'] =original_btc_train['market cap'].str.replace(',', '')\n",
    "original_btc_train['market cap'] =pd.to_numeric(original_btc_train['market cap'].str.replace('$', ''))\n",
    "original_btc_train['market cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.575928Z",
     "iopub.status.busy": "2021-06-23T22:24:38.575463Z",
     "iopub.status.idle": "2021-06-23T22:24:38.60138Z",
     "shell.execute_reply": "2021-06-23T22:24:38.599994Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.575881Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_btc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.603792Z",
     "iopub.status.busy": "2021-06-23T22:24:38.603422Z",
     "iopub.status.idle": "2021-06-23T22:24:38.63476Z",
     "shell.execute_reply": "2021-06-23T22:24:38.633501Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.60376Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_btc_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.637146Z",
     "iopub.status.busy": "2021-06-23T22:24:38.636681Z",
     "iopub.status.idle": "2021-06-23T22:24:38.647844Z",
     "shell.execute_reply": "2021-06-23T22:24:38.646536Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.637097Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_btc_train['market cap'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.650362Z",
     "iopub.status.busy": "2021-06-23T22:24:38.649773Z",
     "iopub.status.idle": "2021-06-23T22:24:38.675877Z",
     "shell.execute_reply": "2021-06-23T22:24:38.675042Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.650306Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_train = original_btc_train.set_index('file_name')\n",
    "btc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.677586Z",
     "iopub.status.busy": "2021-06-23T22:24:38.677256Z",
     "iopub.status.idle": "2021-06-23T22:24:38.691488Z",
     "shell.execute_reply": "2021-06-23T22:24:38.690082Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.677557Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap = btc_train[['market cap']]\n",
    "market_cap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Rolling Mean (Moving Average) ‚Äî to determine trend\n",
    "\n",
    "A simple moving average, also called a rolling or running average is formed by computing the average price of a security over a specific number of periods. Most moving averages are based on closing prices; for example, a 5-day simple moving average is the five-day sum of closing prices divided by five. As its name implies, a moving average is an average that moves. Old data is dropped as new data becomes available, causing the average to move along the time scale. The example below shows a 5-day moving average evolving over three days.\n",
    "\n",
    "```\n",
    "Daily Closing Prices: 11,12,13,14,15,16,17\n",
    "\n",
    "First day of 5-day SMA: (11 + 12 + 13 + 14 + 15) / 5 = 13\n",
    "\n",
    "Second day of 5-day SMA: (12 + 13 + 14 + 15 + 16) / 5 = 14\n",
    "\n",
    "Third day of 5-day SMA: (13 + 14 + 15 + 16 + 17) / 5 = 15\n",
    "```\n",
    "\n",
    "![img](https://i.imgur.com/TpOZqYb.png)\n",
    "\n",
    "The first day of the moving average simply covers the last five days. The second day of the moving average drops the first data point (11) and adds the new data point (16).\n",
    "\n",
    "So the simple moving average is the unweighted mean of the previous M data points. The selection of M (sliding window) depends on the amount of smoothing desired since increasing the value of M improves the smoothing at the expense of accuracy.\n",
    "\n",
    "The moving average is used to analyze the time-series data by calculating averages of different subsets of the complete dataset. Since it involves taking the average of the dataset over time, it is also called a moving mean (MM) or rolling mean. Moving averages are widely used in finance to determine trends in the market and in environmental engineering to evaluate standards for environmental quality such as the concentration of pollutants.\n",
    "\n",
    "The easiest way to calculate the simple moving average is by using the pandas.Series.rolling method. This method provides rolling windows over the data. On the resulting windows, we can perform calculations using a statistical function (in this case the mean). The size of the window (number of periods) is specified in the argument window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.693264Z",
     "iopub.status.busy": "2021-06-23T22:24:38.692925Z",
     "iopub.status.idle": "2021-06-23T22:24:38.712644Z",
     "shell.execute_reply": "2021-06-23T22:24:38.711765Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.693233Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap.rolling(window=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.714451Z",
     "iopub.status.busy": "2021-06-23T22:24:38.714088Z",
     "iopub.status.idle": "2021-06-23T22:24:38.745001Z",
     "shell.execute_reply": "2021-06-23T22:24:38.743891Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.714419Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap['ma_rolling_3-Day'] = market_cap['market cap'].rolling(window=3).mean().shift(1)\n",
    "market_cap['ma_rolling_30-Day'] = market_cap['market cap'].rolling(window=30).mean().shift(1)\n",
    "market_cap['ma_rolling_3-Months'] = market_cap['market cap'].rolling(window=90).mean().shift(1)\n",
    "market_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:38.749668Z",
     "iopub.status.busy": "2021-06-23T22:24:38.749149Z",
     "iopub.status.idle": "2021-06-23T22:24:39.406574Z",
     "shell.execute_reply": "2021-06-23T22:24:39.40534Z",
     "shell.execute_reply.started": "2021-06-23T22:24:38.749611Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = ['steelblue', 'red', 'purple', 'black']\n",
    "\n",
    "market_cap.plot(color=colors, linewidth=2, figsize=(20,6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Weighted moving average\n",
    "\n",
    "Weighted moving average = (t weighting factor) + ((t-1) weighting factor-1) + ((t-n) * weighting factor-n)/n\n",
    "\n",
    "**weighted moving average assigns a specific weight or frequency to each observation, with the most recent observation being assigned a greater weight than those in the distant past to obtain the average.**\n",
    "\n",
    "**Example**\n",
    "\n",
    "Assume that the number of periods is 10, and we want a weighted moving average of four stock prices of $70, $66, $68, and $69, with the first price being the most recent.\n",
    "\n",
    "Using the information given, the most recent weighting will be 4/10, the previous period before that will be 3/10, and the next period before that will be 2/10, and the initial period weighting will be 1/10.\n",
    "\n",
    "The weighting average for the four different prices will be calculated as follows:\n",
    "\n",
    "#### WMA = [70 x (4/10)] + [66 x (3/10)] + [68 x (2/10)] + [69 x (1/10)]\n",
    "\n",
    "WMA = $28 + $19.80 + $13.60 + $6.90 = $68.30\n",
    "\n",
    "![img](https://i.imgur.com/MZO1bbC.png)\n",
    "\n",
    "The accuracy of this model depends largely on your choice of weighting factors. If the time series pattern changes, you must also adapt the weighting factors.\n",
    "\n",
    "When creating a weighting group, you enter the weighting factors as percentages. The sum of the weighting factors does not have to be 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:39.409338Z",
     "iopub.status.busy": "2021-06-23T22:24:39.408815Z",
     "iopub.status.idle": "2021-06-23T22:24:44.944821Z",
     "shell.execute_reply": "2021-06-23T22:24:44.943536Z",
     "shell.execute_reply.started": "2021-06-23T22:24:39.409287Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mov_avg(weights):\n",
    "    def calc(x):\n",
    "        return (weights*x).mean()\n",
    "    return calc\n",
    "\n",
    "market_cap['market cap'].rolling(window=3).apply(weighted_mov_avg(np.array([0.5,1,1.5]))).shift(1)\n",
    "\n",
    "market_cap['wma_rolling_3'] = market_cap['market cap'].rolling(window=3).apply(weighted_mov_avg(np.array([0.5,1,1.5]))).shift(1)\n",
    "market_cap.plot(color=colors, linewidth=2, figsize=(20,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Exponentially weighted moving average (EMA)\n",
    "\n",
    "![img](https://i.imgur.com/bFRUfN3.png)\n",
    "\n",
    "The formula states that the value of the moving average(S) at time t is a mix between the value of raw signal(x) at time t and the previous value of the moving average itself i.e. t-1. It is basically a value between the previous EMA and the current price The degree of mixing is controlled by the parameter a (value between 0‚Äì1).\n",
    "\n",
    "The 'a' in the above is called the smoothing factor and sometime also denonted as  **ùõº** ( alpha ) is defined as:\n",
    "\n",
    "![img](https://i.imgur.com/DCXU7Vc.jpg)\n",
    "\n",
    "where ùëõ is the number of days in our span. Therefore, a 10-day EMA will have a smoothing factor:\n",
    "\n",
    "So the above Formulae can also be written as by simpley re-arranging the terms in the above formulae\n",
    "\n",
    "### Exponential moving average = (Closing Price - Previous EMA) * (2/(Alpha + 1)) + Previous EMA\n",
    "\n",
    "So,\n",
    "- if a = 10%(small), most of the contribution will come from the previous value of the signal. In this case, ‚Äúsmoothing‚Äù will be very strong.\n",
    "- if a = 90%(large), most of the contribution will come from the current value of the signal. In this case, ‚Äúsmoothing‚Äù will be minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "By looking at the documentation, we can note that the .ewm() method has an adjust parameter that defaults to True. This parameter adjusts the weights to account for the imbalance in the beginning periods (if you need more detail, see the Exponentially weighted windows section in the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/computation.html#exponentially-weighted-windows))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:44.946817Z",
     "iopub.status.busy": "2021-06-23T22:24:44.946466Z",
     "iopub.status.idle": "2021-06-23T22:24:44.960087Z",
     "shell.execute_reply": "2021-06-23T22:24:44.958616Z",
     "shell.execute_reply.started": "2021-06-23T22:24:44.946782Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap['market cap'].ewm(span=3, adjust=False, min_periods=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:44.962095Z",
     "iopub.status.busy": "2021-06-23T22:24:44.96173Z",
     "iopub.status.idle": "2021-06-23T22:24:44.993874Z",
     "shell.execute_reply": "2021-06-23T22:24:44.992346Z",
     "shell.execute_reply.started": "2021-06-23T22:24:44.962062Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap['ewm_window_3'] = market_cap['market cap'].ewm(span=3, adjust=False, min_periods=0).mean().shift(1)\n",
    "market_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:44.995678Z",
     "iopub.status.busy": "2021-06-23T22:24:44.995318Z",
     "iopub.status.idle": "2021-06-23T22:24:45.28375Z",
     "shell.execute_reply": "2021-06-23T22:24:45.282321Z",
     "shell.execute_reply.started": "2021-06-23T22:24:44.995634Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap[['ewm_window_3']].plot(color=colors, linewidth=2, figsize=(20,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# What Is Exponential Smoothing?\n",
    "\n",
    "Exponential smoothing is a time series forecasting method for univariate data. Exponential smoothing forecasting is a weighted sum of past observations, but the model explicitly uses an exponentially decreasing weight for past observations. Specifically, past observations are weighted with a geometrically decreasing ratio.\n",
    "\n",
    "The underlying idea of an exponential smoothing model is that, at each period, the model will learn a bit from the most recent demand observation and remember a bit of the last forecast it did.\n",
    "\n",
    "The smoothing parameter (or learning rate) alpha will determine how much importance is given to the most recent demand observation.\n",
    "\n",
    "![img](https://i.imgur.com/eL82Ugp.jpg)\n",
    "\n",
    "Where 0 <= alpha <= 1\n",
    "\n",
    "alpha is a ratio (or a percentage) and  of how much importance the model will allocate to the most recent observation compared to the importance of demand history. The one-step-ahead forecast for time  T+1 is a weighted average of all of the observations in the series  y1,‚Ä¶,yT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:45.285743Z",
     "iopub.status.busy": "2021-06-23T22:24:45.28536Z",
     "iopub.status.idle": "2021-06-23T22:24:45.297568Z",
     "shell.execute_reply": "2021-06-23T22:24:45.296539Z",
     "shell.execute_reply.started": "2021-06-23T22:24:45.285706Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap['market cap'].ewm(alpha=0.7, adjust=False, min_periods=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:45.300323Z",
     "iopub.status.busy": "2021-06-23T22:24:45.29981Z",
     "iopub.status.idle": "2021-06-23T22:24:45.330255Z",
     "shell.execute_reply": "2021-06-23T22:24:45.329046Z",
     "shell.execute_reply.started": "2021-06-23T22:24:45.300281Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap['esm_window_3_7'] = market_cap['market cap'].ewm(alpha=0.7, adjust=False, min_periods=3).mean()\n",
    "market_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:45.33203Z",
     "iopub.status.busy": "2021-06-23T22:24:45.331695Z",
     "iopub.status.idle": "2021-06-23T22:24:45.645398Z",
     "shell.execute_reply": "2021-06-23T22:24:45.644306Z",
     "shell.execute_reply.started": "2021-06-23T22:24:45.331997Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap[['esm_window_3_7']].plot(color=colors, linewidth=2, figsize=(20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-23T22:24:45.647504Z",
     "iopub.status.busy": "2021-06-23T22:24:45.647134Z",
     "iopub.status.idle": "2021-06-23T22:24:46.167765Z",
     "shell.execute_reply": "2021-06-23T22:24:46.166352Z",
     "shell.execute_reply.started": "2021-06-23T22:24:45.647471Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_cap[['market cap','esm_window_3_7']].plot(color=colors, linewidth=2, figsize=(20,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Trading Strategy based on Moving Average\n",
    "\n",
    "There are quite a few very popular strategies that Traders regularly executes based on Moving Averages. Lets checkout couple of them.\n",
    "\n",
    "First note the fact  that a moving average timeseries (for both SMA or EMA) lags the actual price behaviour. And also the assumption that when a change in the long term behaviour of the asset occurs, the actual price timeseries will react faster than the EMA one. Therefore, we will consider the crossing of the two as potential trading signals.\n",
    "\n",
    "- When the price of an asset crosses the EMA timeseries of the same from below, we will close any existing short position and go long (buy) one unit of the asset.\n",
    "\n",
    "- And when the price crosses the EMA timeseries from above, we will close any existing long position and go short (sell) one unit of the asset.\n",
    "\n",
    "For some more of these strategies have a look at [this article](https://blackwellglobal.com/3-simple-moving-average-strategies-for-day-trading/)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 944277,
     "sourceId": 1609551,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30019,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 6.248083,
   "end_time": "2024-06-25T17:25:42.930320",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-25T17:25:36.682237",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
